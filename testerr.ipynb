{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\seg\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"vgg19\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        activation=\"sigmoid\",\n",
    "    \n",
    "    )\n",
    "model.load_state_dict(torch.load(\"best_step_model.pth\"))\n",
    "model.to(DEVICE)\n",
    "\n",
    "def unpad_image(padded_image, original_size):\n",
    "    target_height, target_width = padded_image.shape[:2]\n",
    "    original_height, original_width = original_size,original_size\n",
    "    pad_height = target_height - original_height\n",
    "    pad_width = target_width - original_width\n",
    "\n",
    "  \n",
    "    if pad_height > 0:\n",
    "        padded_image = padded_image[:-pad_height, :]\n",
    "    if pad_width > 0:\n",
    "        padded_image = padded_image[:, :-pad_width]\n",
    "\n",
    "    return padded_image\n",
    "def pad_image(image, target_size, pad_value=0):\n",
    "    height, width = image.shape[:2]\n",
    "    target_height, target_width = target_size\n",
    "\n",
    "\n",
    "    pad_height = target_height - (height % target_height)\n",
    "    pad_width = target_width - (width % target_width)\n",
    "\n",
    "   \n",
    "    padded_image = np.pad(image, ((0, pad_height), (0, pad_width), (0, 0)), mode='constant', constant_values=pad_value)\n",
    "\n",
    "    return padded_image\n",
    "def patched_predict(img,model, window_size = 576, stride =288):\n",
    "    \n",
    "    img_pad = pad_image(img,(window_size,window_size),0)\n",
    "  \n",
    "    bound = (window_size - stride)//2\n",
    "    #print(img.shape[0],img.shape[1],img.shape[2])\n",
    "    fullsize_pred = np.zeros((img_pad.shape[0], img_pad.shape[1]))\n",
    "    #tmp_arr = np.full((img.shape[0], img.shape[1]), channel-1)\n",
    "    #fullsize_pred = y_pred=to_categorical(tmp_arr, num_classes=channel)\n",
    "\n",
    "    row=(img_pad.shape[0] - 2*bound)//stride\n",
    "    column=(img_pad.shape[1] - 2*bound)//stride\n",
    "    #model_class = util.load_model('/home/vivente/Desktop/TEZ/Code/segmentation/out_classification/2021_November_27-15_57_51/fcn_trained_model')\n",
    "    #model_class = 0\n",
    "    \n",
    "    for i in range(row):\n",
    "        for j in range(column):\n",
    "            #print(i,j)\n",
    "            x_start = (i*stride)\n",
    "            x_stop = x_start + window_size\n",
    "            y_start = (j*stride)\n",
    "            y_stop = y_start + window_size\n",
    "            bx_start = x_start + bound\n",
    "            bx_stop  = x_stop - bound\n",
    "            by_start = y_start + bound\n",
    "            by_stop  = y_stop - bound\n",
    "            #print(x_start,x_stop,y_start,y_stop)\n",
    "            #print(bx_start,bx_stop,by_start,by_stop)\n",
    "            pred_in = img_pad[x_start:x_stop, y_start:y_stop,:]\n",
    "            preprocessing_fn = smp.encoders.get_preprocessing_fn(\"vgg19\",\"imagenet\")\n",
    "            sample = get_preprocessing(preprocessing_fn,0)(image=pred_in)\n",
    "            pred_in = sample[\"image\"]\n",
    "            pred_in = torch.from_numpy(pred_in).to(DEVICE).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                part_pred = model.predict(pred_in).cpu().numpy().astype(np.float32)\n",
    "    \n",
    "            \n",
    "            #part_pred_class = model_class.predict(np.reshape(pred_in, (1,window_size, window_size, 3)))\n",
    "            #if(part_pred_class<0.5\n",
    "            #if(y_patch.max()!=0):\n",
    "            #    part_pred = model.predict(np.reshape(pred_in, (1,window_size, window_size, 3)))\n",
    "            #else:\n",
    "            #    part_pred = background_array\n",
    "            part_pred = np.reshape(part_pred, (window_size, window_size))\n",
    "            #print(np.shape(part_pred))\n",
    "            ################ Koseler ###############\n",
    "            if(i==0 and j== 0):                     #####baslangic kÃ¶sesi\n",
    "                valid_part = part_pred[0:window_size - bound, 0:window_size - bound]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[0:bx_stop, 0:by_stop] = valid_part\n",
    "            elif(i==0 and j== column-1):            #####sag kose\n",
    "                valid_part = part_pred[0:window_size - bound, bound:window_size]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[0:bx_stop, by_start:y_stop] = valid_part\n",
    "            elif(i==row-1 and j==column-1):         ####sag alt kose\n",
    "                valid_part = part_pred[bound:window_size, bound:window_size]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[bx_start:x_stop, by_start:y_stop] = valid_part\n",
    "            elif(i==row-1 and j==0):                ####sol alt kose\n",
    "                valid_part = part_pred[bound:window_size, 0:window_size - bound]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[bx_start:x_stop, y_start:by_stop] = valid_part\n",
    "            ################ Kenarlar ##############\n",
    "            elif(i==0 and j!=0 and j!= column-1):   #####ust kenar\n",
    "                valid_part = part_pred[0:window_size - bound, bound:window_size - bound]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[0:bx_stop, by_start:by_stop] = valid_part\n",
    "            elif(j==0 and i!=0 and i!=row-1):       #####sol kenar\n",
    "                valid_part = part_pred[bound:window_size - bound, 0:window_size - bound]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[bx_start:bx_stop, 0:by_stop] = valid_part\n",
    "            elif(i==row-1 and j!=column-1 and j!=0):####alt kenar\n",
    "                valid_part = part_pred[bound:window_size, bound:window_size - bound]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[bx_start:x_stop, by_start:by_stop] = valid_part\n",
    "            elif(j==column-1 and i!=row-1 and i!=0):#####sag kenar\n",
    "                valid_part = part_pred[bound:window_size - bound, bound:window_size]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[bx_start:bx_stop, by_start:y_stop] = valid_part\n",
    "\n",
    "            else:\n",
    "                valid_part = part_pred[bound:window_size - bound, bound:window_size - bound]\n",
    "                #print(np.shape(valid_part))\n",
    "                fullsize_pred[bx_start:bx_stop, by_start:by_stop] = valid_part\n",
    "\n",
    "        unpad_fullsize_pred = unpad_image(fullsize_pred,img.shape[1])\n",
    "\n",
    "    '''\n",
    "    print(\"Full size prediction completed\")\n",
    "    colour_img_pred = util.colorize_binary_img(fullsize_pred)\n",
    "    plt.imshow(colour_img_pred)\n",
    "    plt.show()\n",
    "    '''\n",
    "\n",
    "    return np.asarray(unpad_fullsize_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_img = \"c:/Users/PC/Desktop/Short_Data/Denoised/all_4096/test\"\n",
    "dir_mask = \"c:/Users/PC/Desktop/Short_Data/labels/test/\"\n",
    "imgs = natsorted(os.listdir(dir_img))\n",
    "masks = [file for file in natsorted(os.listdir(dir_mask)) if file.lower().endswith(\".png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5221160435935369\n",
      "0.3865593968107336\n",
      "0.2450918962343069\n",
      "0.399892076472226\n",
      "0.5636194432461155\n",
      "0.5145801177126483\n",
      "0.33200653395805235\n",
      "0.43046757992699025\n",
      "0.17903923979662217\n",
      "0.5671291538584791\n",
      "0.4939010750016446\n",
      "0.5117372853796518\n",
      "0.5535995577748445\n",
      "0.2247010345030402\n",
      "0.39195369708608285\n",
      "0.3369751763830536\n",
      "0.4210289034533834\n",
      "0.5089619048109694\n",
      "0.4746420857072725\n",
      "0.4738304365827869\n",
      "0.5515793741396607\n",
      "0.561084703286008\n",
      "0.5083019317361156\n",
      "0.5476533943337758\n",
      "0.4532640939221185\n",
      "0.5030988578130634\n",
      "0.3147051749692096\n",
      "Average AUC-PR: 0.44338963587008856\n"
     ]
    }
   ],
   "source": [
    "total_auc_pr = 0\n",
    "for img, mask in zip(imgs, masks):\n",
    "    img = cv2.imread(f\"{dir_img}/{img}\")\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    gt = cv2.imread(f\"{dir_mask}/{mask}\", cv2.IMREAD_GRAYSCALE)\n",
    "    gt = np.where(gt == 3, 1, 0)\n",
    "    \n",
    "    a = patched_predict(img, model, 384, 192)\n",
    "    \n",
    "    auc_pr = calculate_auc_pr(gt, a)\n",
    "    print(auc_pr)\n",
    "    total_auc_pr += auc_pr\n",
    "\n",
    "average_auc_pr = total_auc_pr / len(imgs)\n",
    "print(f\"Average AUC-PR: {average_auc_pr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
