{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\seg\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils import *\n",
    "from natsort import natsorted\n",
    "from torch.utils.data import Dataset\n",
    "from Get_model_and_data import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.a = nn.Parameter(torch.tensor(0.5))\n",
    "        self.b = nn.Parameter(torch.tensor(0.5))\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.a * x + self.b * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cpu\"\n",
    "train_mask_dir = \"c:/Users/PC/Desktop/square/label_zoom_1_0_1/train\"\n",
    "array_folder_local = f\"C:/Users/PC/Desktop/Segmentation/out/2024_May_18-11_51_34/pred_probs_caglar_he_train\"\n",
    "array_folder_global = f\"C:/Users/PC/Desktop/Segmentation/out/2024_May_18-11_58_31/pred_probs_caglar_he_train\"\n",
    "\n",
    "dataset = Global_Local_Dataset(array_folder_local, array_folder_global, train_mask_dir)\n",
    "train_loader = DataLoader(dataset, batch_size=1, shuffle=True, drop_last=True)\n",
    "\n",
    "model = LinearModel().to(device)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.5**(epoch // 15))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_values_from_arrays(folder_path):\n",
    "    max_values = []\n",
    "\n",
    "    # List all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.npy'):  \n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "            # Load the array\n",
    "            array = np.load(file_path)\n",
    "            \n",
    "           \n",
    "            max_value = np.max(array)\n",
    "            \n",
    "          \n",
    "            max_values.append(max_value)\n",
    "    \n",
    "    return max_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = get_max_values_from_arrays(f\"C:/Users/PC/Desktop/Segmentation/out/2024_May_18-11_58_31/pred_probs_caglar_he_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (local_global_features, masks) in enumerate(train_loader):\n",
    "        print(f\"Batch {batch_idx+1}\")\n",
    "        print(f\"Local Features Shape: {local_global_features.shape}\")\n",
    "        print(f\"Masks Shape: {masks.shape}\")\n",
    "        print(torch.max(local_global_features[0][1]),torch.max(local_global_features[0][0]))\n",
    "        print(local_global_features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for merged_array, gt_mask in train_loader:\n",
    "        merged_array, gt_mask = merged_array.to(device), gt_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(merged_array[0].float(),merged_array[1].float())\n",
    "        loss = criterion(output, gt_mask.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "    print(f\"Epoch {epoch+1}, Coefficients: a = {model.a.item()}, b = {model.b.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_save_results(global_dir, local_dir, model_path, device, saved_prob_dir,saved_mask_dir,gt_folder_test):\n",
    "    if not os.path.exists(saved_prob_dir):\n",
    "        os.makedirs(saved_prob_dir, exist_ok=True)\n",
    "    if not os.path.exists(saved_mask_dir):\n",
    "        os.makedirs(saved_mask_dir, exist_ok=True)\n",
    "\n",
    "    model = LinearModel().to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    array_folder_local = f\"{local_dir}/pred_probs_caglar_he\"\n",
    "    array_folder_global = f\"{global_dir}/pred_probs_caglar_he\"\n",
    "    \n",
    "\n",
    "    dataset = Global_Local_Dataset(array_folder_local, array_folder_global, gt_folder_test)\n",
    "    data_loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (merged_array, gt_mask) in enumerate(data_loader):\n",
    "            merged_array = merged_array.to(device)\n",
    "            output = model(merged_array.float())\n",
    "            output_np = output.cpu().numpy().squeeze()\n",
    "\n",
    "            save_path = os.path.join(saved_prob_dir, f\"prediction_{idx}.npy\")\n",
    "            np.save(save_path, output_np)\n",
    "        \n",
    "\n",
    "            png_save_path = os.path.join(saved_mask_dir, f\"prediction_{idx}.png\")\n",
    "            output_bool = (output_np > 0.5).astype(np.uint8)\n",
    "            output_img = (output_bool * 255).astype(np.uint8)\n",
    "            cv2.imwrite(png_save_path, output_img)\n",
    "        print(f\"Prediction masks are  saved\")\n",
    "        print(f\"Prediction images are saved\")\n",
    "\n",
    "# Set device and directories\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_mask_directory = \"c:/Users/PC/Desktop/square/label_zoom_1_0_1/train\"\n",
    "global_dir = \"C:/Users/PC/Desktop/Segmentation/out/2024_May_18-11_58_31/\"\n",
    "local_dir = \"C:/Users/PC/Desktop/Segmentation/out/2024_May_18-11_51_34/\"\n",
    "save_model_path = \"Final_model_results/\"\n",
    "saved_prob_dir = f\"{save_model_path}prob_arrays/\"\n",
    "saved_mask_dir = f\"{save_model_path}mask_arrays/\"\n",
    "gt_folder_test = \"c:/Users/PC/Desktop/square/label_zoom_1_0_1/test\" \n",
    "gt_mask = \"c:/Users/PC/Desktop/square/label_zoom_1_0_1/train/\" \n",
    "# Train the model and save it\n",
    "global_local_prob_model(train_mask_directory,global_dir, local_dir, device, save_model_path)\n",
    "\n",
    "# Load the model, make predictions, and save them\n",
    "predict_and_save_results(global_dir, local_dir, f\"{save_model_path}best_model.pth\", device, saved_prob_dir,saved_mask_dir,gt_folder_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.834802"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Array = np.load(\"C:/Users/PC/Desktop/Segmentation/IDRiD-Eye-Fundus-Dataset-Lesion-Segmentation/Final_model_results/prob_arrays/prediction_1.npy\")\n",
    "np.max(test_Array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Plotting mismatches: 27it [00:07,  3.68it/s]\n",
      "2024-05-18 19:40:23,811 - root - INFO - Plotting and saving mismatches completed successfully.\n"
     ]
    }
   ],
   "source": [
    "plot_save_mismatches(\"C:/Users/PC/Desktop/Segmentation/IDRiD-Eye-Fundus-Dataset-Lesion-Segmentation/Final_model_results/mask_arrays\",\n",
    "                     gt_folder_test,\n",
    "                     \"C:/Users/PC/Desktop/Segmentation/IDRiD-Eye-Fundus-Dataset-Lesion-Segmentation/Final_model_results\",\n",
    "                     mismatched_images=\"mismatched_images_caglar\")\n",
    "logging.info(\"Plotting and saving mismatches completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pr_result_paper_caglar,_,_= auc_pr_paper_calculation(pred_mask_dir=\"C:/Users/PC/Desktop/Segmentation/IDRiD-Eye-Fundus-Dataset-Lesion-Segmentation/Final_model_results/prob_arrays\", \n",
    "                                                        test_mask_dir=gt_folder_test,\n",
    "                                                        \n",
    "                                                        stride=576)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5903840984589883"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_pr_result_paper_caglar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pr_result_paper_caglar,_,_= auc_pr_paper_calculation(pred_mask_dir=log_dir+f\"pred_probs_caglar_{dataset_conf['data']}\", \n",
    "                                                                                        test_mask_dir=os.path.join(dataset_conf['test_mask_dir'],\n",
    "                                                                                                                    dataset_conf['data']), \n",
    "                                                                                                                    stride=dataset_conf['stride'])\n",
    "logging.info(\"AUC-PR calculation according to paper completed successfully.\")\n",
    "metrics_caglar = calculate_metrics(os.path.join(dataset_conf['test_mask_dir'],\n",
    "                                                dataset_conf['data']), \n",
    "                                                log_dir+f\"pred_masks_caglar_{dataset_conf['data']}\")\n",
    "logging.info(\"Metrics calculation completed successfully.\")\n",
    "#wandb.log(wandb_final_log(auc_pr_caglar=auc_pr_result_paper_caglar,metrics_caglar=metrics_caglar))\n",
    "results = { \"auc_pr\":auc_pr_result_paper_caglar,\"metrics\":metrics_caglar}\n",
    "json_file_path = os.path.join(log_dir, 'results.json')\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(results, json_file, indent=4)\n",
    "logging.info(\"Results saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
